{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dda9a9ce",
   "metadata": {},
   "source": [
    "## Dataset 1: MovieLens 100K (Explicit Ratings)\n",
    "\n",
    "### ðŸ”¹ Setup Summary\n",
    "- **Data type:** Explicit ratings (1â€“5 stars)\n",
    "- **Training/Test Split:** [e.g., u1.base & u1.test (80/20 split)]\n",
    "- **Parameters Tested:** \n",
    "- **Evaluation Metrics:** RMSE, MAE, Precision@5, Recall@5, Precision@10, Recall@10, NDCG@10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13757ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.spatial.distance import pdist, squareform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f235b827",
   "metadata": {},
   "source": [
    "# 1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed03eeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 4) (20000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>874965758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1        1       5  874965758\n",
       "1        1        2       3  876893171\n",
       "2        1        3       4  878542960\n",
       "3        1        4       3  876893119\n",
       "4        1        5       3  889751712"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#familiar with the train and test data\n",
    "train = pd.read_csv('ml-100k/u1.base', sep='\\t',\n",
    "                    names=['user_id','item_id','rating','timestamp'])\n",
    "test  = pd.read_csv('ml-100k/u1.test', sep='\\t',\n",
    "                    names=['user_id','item_id','rating','timestamp'])\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "793c9d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n",
      "100000 ratings\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#familiar with the data\n",
    "with open('ml-100k/u.info', 'r') as f:\n",
    "    info = f.read()\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cd2df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movie_id              title release_date  video_release_date  \\\n",
      "0         1   Toy Story (1995)  01-Jan-1995                 NaN   \n",
      "1         2   GoldenEye (1995)  01-Jan-1995                 NaN   \n",
      "2         3  Four Rooms (1995)  01-Jan-1995                 NaN   \n",
      "3         4  Get Shorty (1995)  01-Jan-1995                 NaN   \n",
      "4         5     Copycat (1995)  01-Jan-1995                 NaN   \n",
      "\n",
      "                                            IMDb_URL  unknown  Action  \\\n",
      "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n",
      "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
      "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...        0       0   \n",
      "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...        0       1   \n",
      "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)        0       0   \n",
      "\n",
      "   Adventure  Animation  Children's  ...  Fantasy  Film-Noir  Horror  Musical  \\\n",
      "0          0          1           1  ...        0          0       0        0   \n",
      "1          1          0           0  ...        0          0       0        0   \n",
      "2          0          0           0  ...        0          0       0        0   \n",
      "3          0          0           0  ...        0          0       0        0   \n",
      "4          0          0           0  ...        0          0       0        0   \n",
      "\n",
      "   Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
      "0        0        0       0         0    0        0  \n",
      "1        0        0       0         1    0        0  \n",
      "2        0        0       0         1    0        0  \n",
      "3        0        0       0         0    0        0  \n",
      "4        0        0       0         1    0        0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "#familiar with the movie data\n",
    "column_names = [\n",
    "    'movie_id', 'title', 'release_date', 'video_release_date', 'IMDb_URL',\n",
    "    'unknown', 'Action', 'Adventure', 'Animation', \"Children's\",\n",
    "    'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir',\n",
    "    'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller',\n",
    "    'War', 'Western'\n",
    "]\n",
    "\n",
    "u_item = pd.read_csv('ml-100k/u.item', sep='|', names=column_names, encoding='latin-1')\n",
    "print(u_item.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d002e",
   "metadata": {},
   "source": [
    "# 2. Create user-item matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d5ee6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "      <th>1682</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
       "user_id                                                              ...   \n",
       "1         5.0   3.0   4.0   3.0   3.0   NaN   4.0   1.0   5.0   NaN  ...   \n",
       "2         4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...   \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "\n",
       "item_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
       "user_id                                                              \n",
       "1         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "5         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 1682 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_users = np.union1d(train['user_id'].unique(), test['user_id'].unique())\n",
    "all_items = np.union1d(train['item_id'].unique(), test['item_id'].unique())\n",
    "\n",
    "# Pivot train matrix\n",
    "train_matrix = train.pivot(index='user_id', columns='item_id', values='rating')\n",
    "train_matrix = train_matrix.reindex(index=all_users, columns=all_items, fill_value=0)\n",
    "train_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85ad25d",
   "metadata": {},
   "source": [
    "# 3. user-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "661f2ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_based_similarity(matrix, method='cosine'):\n",
    "    if method == 'cosine':\n",
    "        sim = cosine_similarity(matrix.values)\n",
    "    elif method == 'pearson':\n",
    "        sim = fast_pearson_similarity(matrix)\n",
    "    elif method == 'euclidean':\n",
    "        dist = squareform(pdist(matrix.values, metric='euclidean'))\n",
    "        sim = 1 / (1 + dist)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown similarity method\")\n",
    "    return pd.DataFrame(sim, index=matrix.index, columns=matrix.index)\n",
    "\n",
    "def fast_pearson_similarity(matrix):\n",
    "    X = matrix.values\n",
    "    mean_user = X.mean(axis=1, keepdims=True)\n",
    "    X_centered = X - mean_user\n",
    "    numerator = X_centered @ X_centered.T\n",
    "    denom = np.linalg.norm(X_centered, axis=1)\n",
    "    denominator = np.outer(denom, denom)\n",
    "    denominator[denominator == 0] = 1e-8\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2d696cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_based_collaborative_filtering(train_matrix, user_sim, k=None):\n",
    "    X = train_matrix.values\n",
    "    n_users, n_items = X.shape\n",
    "    pred = np.zeros_like(X)\n",
    "    \n",
    "    for u in range(n_users):\n",
    "        if k:\n",
    "            top_k_users = np.argsort(user_sim[u, :])[-(k+1):]\n",
    "            top_k_users = top_k_users[top_k_users != u]\n",
    "        else:\n",
    "            top_k_users = np.arange(n_users)\n",
    "            top_k_users = top_k_users[top_k_users != u]\n",
    "        \n",
    "        for i in range(n_items):\n",
    "            neighbors = [v for v in top_k_users if X[v, i] > 0]\n",
    "            if neighbors:\n",
    "                weights = user_sim[u, neighbors]\n",
    "                pred[u, i] = np.dot(weights, X[neighbors, i]) / np.sum(np.abs(weights))\n",
    "            else:\n",
    "                pred[u, i] = 0\n",
    "    return pd.DataFrame(pred, index=train_matrix.index, columns=train_matrix.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c7af82",
   "metadata": {},
   "source": [
    "# 4. evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5b44b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(pred_matrix, test_df):\n",
    "    preds, trues = [], []\n",
    "    for row in test_df.itertuples(index=False):\n",
    "        user, item, rating = row.user_id, row.item_id, row.rating\n",
    "        if user in pred_matrix.index and item in pred_matrix.columns:\n",
    "            preds.append(pred_matrix.loc[user, item])\n",
    "            trues.append(rating)\n",
    "    return np.sqrt(np.mean((np.array(preds) - np.array(trues))**2))\n",
    "\n",
    "def mae(pred_matrix, test_df):\n",
    "    preds, trues = [], []\n",
    "    for row in test_df.itertuples(index=False):\n",
    "        user, item, rating = row.user_id, row.item_id, row.rating\n",
    "        if user in pred_matrix.index and item in pred_matrix.columns:\n",
    "            preds.append(pred_matrix.loc[user, item])\n",
    "            trues.append(rating)\n",
    "    return np.mean(np.abs(np.array(preds) - np.array(trues)))\n",
    "\n",
    "def precision_recall_at_k(pred_matrix, test_df, k=5):\n",
    "    precisions, recalls = [], []\n",
    "    for user in test_df['user_id'].unique():\n",
    "        if user not in pred_matrix.index:\n",
    "            continue\n",
    "        # Top-k recommended items\n",
    "        user_preds = pred_matrix.loc[user].sort_values(ascending=False)\n",
    "        top_k_items = user_preds.index[:k]\n",
    "        true_items = test_df[test_df['user_id'] == user]['item_id'].values\n",
    "        hits = len(set(top_k_items) & set(true_items))\n",
    "        precisions.append(hits / k)\n",
    "        recalls.append(hits / len(true_items))\n",
    "    return np.mean(precisions), np.mean(recalls)\n",
    "\n",
    "def ndcg_at_k(pred_matrix, test_df, k=10):\n",
    "    ndcgs = []\n",
    "    for user in test_df['user_id'].unique():\n",
    "        if user not in pred_matrix.index:\n",
    "            continue\n",
    "        user_preds = pred_matrix.loc[user].sort_values(ascending=False)\n",
    "        top_k_items = user_preds.index[:k]\n",
    "        true_items = test_df[test_df['user_id'] == user]['item_id'].values\n",
    "        dcg = sum([1 / np.log2(i + 2) if item in true_items else 0 for i, item in enumerate(top_k_items)])\n",
    "        idcg = sum([1 / np.log2(i + 2) for i in range(min(k, len(true_items)))])\n",
    "        ndcgs.append(dcg / idcg if idcg > 0 else 0)\n",
    "    return np.mean(ndcgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0fcc9c",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5876d360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating similarity: cosine ---\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39272\\2241412578.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n--- Evaluating similarity: {sim} ---\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0muser_sim_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_based_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mk_values\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mpred_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_based_collaborative_filtering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_sim_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39272\\2347120667.py\u001b[0m in \u001b[0;36muser_based_similarity\u001b[1;34m(matrix, method)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0muser_based_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cosine'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cosine'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0msim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'pearson'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0msim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfast_pearson_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\OneDrive - NTU\\OneDrive - Nanyang Technological University\\Documents\\GitHub\\SC4020-data-mining\\.venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1249\u001b[0m     \u001b[1;31m# to avoid recursive import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1251\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\OneDrive - NTU\\OneDrive - Nanyang Technological University\\Documents\\GitHub\\SC4020-data-mining\\.venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m         )\n\u001b[0;32m    155\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\OneDrive - NTU\\OneDrive - Nanyang Technological University\\Documents\\GitHub\\SC4020-data-mining\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\OneDrive - NTU\\OneDrive - Nanyang Technological University\\Documents\\GitHub\\SC4020-data-mining\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    114\u001b[0m             raise ValueError(\n\u001b[0;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m--> 116\u001b[1;33m                     \u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m                 )\n\u001b[0;32m    118\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "similarities = ['cosine', 'pearson', 'euclidean']\n",
    "k_values = range(5, 31, 5)\n",
    "\n",
    "results = []\n",
    "\n",
    "for sim in similarities:\n",
    "    print(f\"\\n--- Evaluating similarity: {sim} ---\")\n",
    "    user_sim_matrix = user_based_similarity(train_matrix, method=sim).values\n",
    "    for k in k_values:\n",
    "        pred_matrix = user_based_collaborative_filtering(train_matrix, user_sim_matrix, k=k)\n",
    "        \n",
    "        result = {\n",
    "            'similarity': sim,\n",
    "            'k': k,\n",
    "            'RMSE': rmse(pred_matrix, test),\n",
    "            'MAE': mae(pred_matrix, test),\n",
    "            'P@5': precision_recall_at_k(pred_matrix, test, k=5)[0],\n",
    "            'R@5': precision_recall_at_k(pred_matrix, test, k=5)[1],\n",
    "            'P@10': precision_recall_at_k(pred_matrix, test, k=10)[0],\n",
    "            'R@10': precision_recall_at_k(pred_matrix, test, k=10)[1],\n",
    "            'NDCG@10': ndcg_at_k(pred_matrix, test, k=10)\n",
    "        }\n",
    "        results.append(result)\n",
    "        print(f\"k={k} â†’ RMSE={result['RMSE']:.4f}, MAE={result['MAE']:.4f}, P@5={result['P@5']:.4f}\")\n",
    "\n",
    "  \n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.7.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
